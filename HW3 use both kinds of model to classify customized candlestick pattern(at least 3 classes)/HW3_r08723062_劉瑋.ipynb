{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQRJmRV5x4F9"
   },
   "source": [
    "## 題目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yw5WsOFfx_n-"
   },
   "source": [
    "2. Use LSTM & CNN model to classify customized candlestick pattern (at least 3 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkJTtolxyBL9"
   },
   "source": [
    "### 執行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_apt-eryH5c"
   },
   "source": [
    "所有檔案: candlestick_train_cnn.py、candlestick_train_lstm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arudH7ARykMS"
   },
   "source": [
    "#### 2. Use LSTM model to classify customized candlestick pattern\n",
    "* candlestick_train_lstm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdzGaOrpykzq"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def load_pkl(pkl_name):\n",
    "    # load data from data folder\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes):\n",
    "    x_train = x_train.reshape(-1, n_step, n_input)\n",
    "    x_test = x_test.reshape(-1, n_step, n_input)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "def lstm_model(n_input, n_step, n_hidden, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_hidden, batch_input_shape=(None, n_step, n_input), unroll=True))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "def train_lstm(model, x_train, y_train, x_test, y_test, \n",
    "        learning_rate, training_iters, batch_size):\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam,\n",
    "        loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "        batch_size=batch_size, epochs=training_iters,\n",
    "        verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "def print_result(data, x_train, x_test, model):\n",
    "    # get train & test pred-labels\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    # get train & test true-labels\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "\n",
    "def mnist_lstm_main():\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = 10\n",
    "    batch_size = 128\n",
    "\n",
    "    # model parameters\n",
    "    n_input = 40\n",
    "    n_step = 10\n",
    "    n_hidden = 256\n",
    "    n_classes = 10\n",
    "#/label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl\n",
    "    data = load_pkl('/label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl')\n",
    "    x_train, y_train, x_test, y_test = data['train_gaf'], data['train_label'][:, 0], data['test_gaf'], data['test_label'][:, 0]\n",
    "    x_train, x_test, y_train, y_test = lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes)\n",
    "\n",
    "    model = lstm_model(n_input, n_step, n_hidden, n_classes)\n",
    "    train_lstm(model, x_train, y_train, x_test, y_test, learning_rate, \n",
    "               training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('LSTM test accuracy:', scores[1])\n",
    "    print_result(data, x_train, x_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "opeqD8lfzBpZ",
    "outputId": "364f5a4d-3087-4e7b-824c-4d8c62b90b45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               304128    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 306,698\n",
      "Trainable params: 306,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "118/118 [==============================] - 11s 80ms/step - loss: 2.2088 - accuracy: 0.1919 - val_loss: 1.6876 - val_accuracy: 0.2628\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 9s 76ms/step - loss: 1.5854 - accuracy: 0.3153 - val_loss: 1.3625 - val_accuracy: 0.4158\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 9s 76ms/step - loss: 1.3546 - accuracy: 0.4102 - val_loss: 1.2171 - val_accuracy: 0.4990\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 9s 76ms/step - loss: 1.1797 - accuracy: 0.5089 - val_loss: 1.0610 - val_accuracy: 0.5680\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 9s 77ms/step - loss: 0.9983 - accuracy: 0.6150 - val_loss: 0.8818 - val_accuracy: 0.6436\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 9s 77ms/step - loss: 0.7947 - accuracy: 0.6999 - val_loss: 0.6540 - val_accuracy: 0.7520\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 9s 76ms/step - loss: 0.7078 - accuracy: 0.7278 - val_loss: 0.5994 - val_accuracy: 0.7628\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 9s 76ms/step - loss: 0.6762 - accuracy: 0.7383 - val_loss: 0.6462 - val_accuracy: 0.7472\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 10s 82ms/step - loss: 0.6387 - accuracy: 0.7530 - val_loss: 0.5650 - val_accuracy: 0.7766\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 9s 76ms/step - loss: 0.5978 - accuracy: 0.7688 - val_loss: 0.5175 - val_accuracy: 0.8118\n",
      "LSTM test accuracy: 0.8118000030517578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1615  183  153  158   92  385  212  135   67]\n",
      " [  72 1335    0   93    0    0    0    0    0]\n",
      " [ 169    0 1314    0   17    0    0    0    0]\n",
      " [  30   26    0 1139    0    0    0  305    0]\n",
      " [  76    0   61    0 1286    0    0    0   77]\n",
      " [ 109    3    0    2    0 1322    2   62    0]\n",
      " [ 155    1    1    0    6    0 1269    0   68]\n",
      " [  19    2    0  111    0   22    0 1346    0]\n",
      " [  57    0    4    0  234    0   42    0 1163]] \n",
      "\n",
      " [[555  42  63  52  31 132  56  46  23]\n",
      " [ 22 447   0  31   0   0   0   0   0]\n",
      " [ 46   0 450   0   4   0   0   0   0]\n",
      " [ 18   4   0 390   0   0   0  88   0]\n",
      " [ 24   0  28   0 428   0   0   0  20]\n",
      " [ 35   0   0   0   0 457   0   8   0]\n",
      " [ 44   0   1   0   1   0 441   0  13]\n",
      " [  5   1   0   5   0   8   0 481   0]\n",
      " [ 26   0   0   0  55   0   9   0 410]]\n"
     ]
    }
   ],
   "source": [
    "mnist_lstm_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Qw8mi9e2rFI"
   },
   "source": [
    "#### 3. Use CNN model to classify customized candlestick pattern\n",
    "* candlestick_train_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HoHel9bi2rx7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, Activation, MaxPool2D\n",
    "\n",
    "\n",
    "def load_pkl(pkl_name):\n",
    "    # load data from data folder\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def get_cnn_model(params):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(10, 10, 4)))\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def train_model(params, data):\n",
    "    model = get_cnn_model(params)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    hist = model.fit(x=data['train_gaf'], y=data['train_label_arr'],\n",
    "                     batch_size=params['batch_size'], epochs=params['epochs'], verbose=2)\n",
    "    return (model, hist)\n",
    "\n",
    "def print_result(data, model):\n",
    "    # get train & test pred-labels\n",
    "    train_pred = model.predict_classes(data['train_gaf'])\n",
    "    test_pred = model.predict_classes(data['test_gaf'])\n",
    "    # get train & test true-labels\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEZbL3-A2u5s",
    "outputId": "28c7d31b-719b-4692-90b4-6489bd757296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 - 7s - loss: 1.7124 - accuracy: 0.3529\n",
      "Epoch 2/10\n",
      "235/235 - 7s - loss: 0.8493 - accuracy: 0.6951\n",
      "Epoch 3/10\n",
      "235/235 - 6s - loss: 0.6263 - accuracy: 0.7745\n",
      "Epoch 4/10\n",
      "235/235 - 6s - loss: 0.5438 - accuracy: 0.8023\n",
      "Epoch 5/10\n",
      "235/235 - 6s - loss: 0.5044 - accuracy: 0.8171\n",
      "Epoch 6/10\n",
      "235/235 - 7s - loss: 0.4736 - accuracy: 0.8275\n",
      "Epoch 7/10\n",
      "235/235 - 7s - loss: 0.4546 - accuracy: 0.8340\n",
      "Epoch 8/10\n",
      "235/235 - 7s - loss: 0.4352 - accuracy: 0.8409\n",
      "Epoch 9/10\n",
      "235/235 - 7s - loss: 0.4196 - accuracy: 0.8471\n",
      "Epoch 10/10\n",
      "235/235 - 7s - loss: 0.4108 - accuracy: 0.8503\n",
      "CNN test accuracy: 0.8575999736785889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2257  124  115   91   97  102   73   96   45]\n",
      " [  25 1474    0    1    0    0    0    0    0]\n",
      " [  74    0 1418    0    8    0    0    0    0]\n",
      " [  64   61    0 1292    0    0    0   83    0]\n",
      " [  66    0   29    0 1342    0    5    0   58]\n",
      " [  79    1    0    0    0 1383    1   36    0]\n",
      " [ 172    2    2    0    2    0 1298    0   24]\n",
      " [  44   10    0  139    0    8    0 1299    0]\n",
      " [ 107    0    2    0  190    0   46    0 1155]] \n",
      "\n",
      " [[753  36  45  28  33  34  15  39  17]\n",
      " [  9 491   0   0   0   0   0   0   0]\n",
      " [ 22   0 478   0   0   0   0   0   0]\n",
      " [ 26  20   0 426   0   0   0  28   0]\n",
      " [ 35   0  10   0 424   0   1   0  30]\n",
      " [ 32   1   0   0   0 460   0   7   0]\n",
      " [ 74   0   1   0   0   0 423   0   2]\n",
      " [ 20   1   0  29   0   5   0 445   0]\n",
      " [ 52   0   0   0  45   0  15   0 388]]\n"
     ]
    }
   ],
   "source": [
    "PARAMS = {}\n",
    "PARAMS['pkl_name'] = '/label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl'\n",
    "PARAMS['classes'] = 9\n",
    "PARAMS['lr'] = 0.01\n",
    "PARAMS['epochs'] = 10\n",
    "PARAMS['batch_size'] = 64\n",
    "PARAMS['optimizer'] = optimizers.SGD(lr=PARAMS['lr'])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# load data & keras model\n",
    "data = load_pkl(PARAMS['pkl_name'])\n",
    "# train cnn model\n",
    "model, hist = train_model(PARAMS, data)\n",
    "# train & test result\n",
    "scores = model.evaluate(data['test_gaf'], data['test_label_arr'], verbose=0)\n",
    "print('CNN test accuracy:', scores[1])\n",
    "print_result(data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0zfen-o3Nnm"
   },
   "source": [
    "## Reference"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
